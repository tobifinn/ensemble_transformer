defaults:
  - optimizer: adam
  - scheduler: plateau
  - transformer: softmax

_recursive_: False
_target_: ens_transformer.transformer_net.TransformerNet
n_transformers: 1
hidden_channels: 64
learning_rate: ${learning_rate}

embedding:
  _target_: ens_transformer.embedding.ModelEmbedding
  n_channels:
    - 64
    - 64
    - 64
  filter_size: 5
  activation: torch.nn.SELU
